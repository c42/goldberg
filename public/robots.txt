# See http://www.robotstxt.org/wc/norobots.html for documentation on how to use the robots.txt file
#
# This should block the spiders to crawl all pages except /
User-Agent: *
Disallow: /projects/
Disallow: /images/
Disallow: /javascript/
Disallow: /stlyesheets/
Allow: /